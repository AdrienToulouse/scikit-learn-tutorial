{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv(os.path.join('datasets', 'cps_85_wages.csv'))\n",
    "target_name = \"WAGE\"\n",
    "target = df[target_name].to_numpy()\n",
    "data = df.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "df_train, df_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing\n",
    "\n",
    "binary_encoding_columns = ['MARR', 'SEX', 'SOUTH', 'UNION']\n",
    "one_hot_encoding_columns = ['OCCUPATION', 'SECTOR', 'RACE']\n",
    "scaling_columns = ['AGE', 'EDUCATION', 'EXPERIENCE']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('binary-encoder', OrdinalEncoder(), binary_encoding_columns),\n",
    "    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'),\n",
    "     one_hot_encoding_columns),\n",
    "    ('standard-scaler', StandardScaler(), scaling_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocessor, Ridge(alpha=1))\n",
    "start = time.time()\n",
    "model.fit(df_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(df_test, target_test):.2f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocessor, Ridge(alpha=10000))\n",
    "start = time.time()\n",
    "model.fit(df_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(df_test, target_test):.2f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use grid-search\n",
    "model = make_pipeline(preprocessor, Ridge())\n",
    "param_grid = {'ridge__alpha': np.linspace(0.001, 1000, num=20)}\n",
    "model_grid_search = GridSearchCV(model, param_grid=param_grid)\n",
    "start = time.time()\n",
    "model_grid_search.fit(df_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model_grid_search.__class__.__name__} is \"\n",
    "    f\"{model_grid_search.score(df_test, target_test):.2f} with a fitting time \"\n",
    "    f\"of {elapsed_time:.3f} seconds\"\n",
    ")\n",
    "print(f\"The best set of parameters is: {model_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly we could use a random-search\n",
    "model = make_pipeline(preprocessor, Ridge())\n",
    "param_distributions = {'ridge__alpha': uniform(loc=50, scale=100)}\n",
    "model_grid_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, n_iter=20\n",
    ")\n",
    "start = time.time()\n",
    "model_grid_search.fit(df_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model_grid_search.__class__.__name__} is \"\n",
    "    f\"{model_grid_search.score(df_test, target_test):.2f} with a fitting time \"\n",
    "    f\"of {elapsed_time:.3f} seconds\"\n",
    ")\n",
    "print(f\"The best set of parameters is: {model_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some predictors come with internal cross-validation to fix hyperparameter\n",
    "# and they are sometimes more efficient than using a grid-search\n",
    "\n",
    "model = make_pipeline(preprocessor, RidgeCV())\n",
    "start = time.time()\n",
    "model.fit(df_train, target_train)\n",
    "print(f\"Time elapsed: {time.time() - start} sec\")\n",
    "\n",
    "param_grid = {\"alpha\": (0.1, 1.0, 10.0)}\n",
    "model = make_pipeline(\n",
    "    preprocessor, GridSearchCV(Ridge(), param_grid=param_grid)\n",
    ")\n",
    "start = time.time()\n",
    "model.fit(df_train, target_train)\n",
    "print(f\"Time elapsed: {time.time() - start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters search in nested cross-validation\n",
    "model = make_pipeline(preprocessor, RidgeCV())\n",
    "start = time.time()\n",
    "score = cross_val_score(model, data, target)\n",
    "print(f\"Time elapsed: {time.time() - start} sec\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "notebooks//ipynb,markdown_files//md,python_scripts//py:percent",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
